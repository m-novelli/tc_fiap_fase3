# Tech Challenge Fase 3 - Ingest√£o de dados + ML + API

Projeto de p√≥s-gradua√ß√£o em Machine Learning Engineering com foco em ingest√£o de dados, desenvolvimento de um modelo de ML e uso produtivo dos resultados

---

## Etapas do Projeto

- Uso dos dados do yfinance de tickers de tecnologia (2007-2025)
- Ingest√£o dos dados da API do yfinance em um data lake na s3
- An√°lise explorat√≥ria dos dados
- Desenvolvimento de Modelos de ML
- Otimiza√ß√£o de Portf√≥lio
- API para devolver o resultado do modelo


---

## üìÅ Estrutura do Projeto

```
üìÇ data/                                    # Script que faz a consulta dos dados do yfinance e alimenta o data lake na s3
üìÇ models/                                  # Analise Exploratoria e Scripts para modelos de previs√£o e resultados
üìÑ requirements.txt                         # Depend√™ncias do projeto
üìÑ An√°lise e Interpreta√ß√£o.md               # An√°lise e Interpreta√ß√£o dos resultados do modelo escolhido
üìÑ api.py                                   # Aplica√ß√£o que executa o modelo de ML atrav√©s da API
üìÑ README.md                                # Documenta√ß√£o do projeto
```

---

## Como executar o projeto

### 1. Clone o reposit√≥rio

```bash
git clone https://github.com/m-novelli/tc_fiap_fase3
cd tc_fiap_fase3
```

### 2. Instale as depend√™ncias

Recomendado usar um ambiente virtual para evitar conflitos de depend√™ncias.

```bash
python -m venv ml_api_venv
source ml_api_venv/bin/activate  # No Windows use: ml_api_venv\Scripts\activate
```

Instalar depend√™ncias:
```bash
pip install -r requirements.txt
```

### 3. Dados salvos localmente

Para o treinamento dos modelos, usamos script para baixar os dados do yfinance e salvar localmente em datas/dados_base.csv (caminho configur√°vel). No momento da predi√ß√£o, o caminho dos dados utilizados √© datas/dados_base_predict.csv.

### 3.1 Alternativa: Usar base do s3

Adicione as credenciais do AWS CLI presentes no AWS Details do AWS Academy Lab no arquivo .aws/credentials
Descomentar as partes que fazem leitura da base local e ajustar para ler direto do s3

```bash
python datas/carga_historica.py
```

### 4. An√°lise explorat√≥ria

Esta etapa foi feita no notebook 0.Analise Exploratoria.ipynb, onde exploramos a base hist√≥rica, trouxemos novas vari√°veis e visualiza√ß√µes para emabasar a modelagem pretidiva

### 5. Modelagem

Foram testados modelos como ARIMA, Random Forest e XGBoost para previs√£o de pre√ßo e retorno de ativos.
O modelo Random Forest foi selecionado para previs√£o de retornos e passou por otimiza√ß√£o de hiperpar√¢metros via Grid Search com valida√ß√£o temporal (TimeSeriesSplit), visando maximizar o desempenho preditivo em s√©ries temporais.

Modelo Final ‚Äì Otimiza√ß√£o de Portf√≥lio com ML:
A estrat√©gia escolhida foi a otimiza√ß√£o de portf√≥lio com base nas previs√µes semanais de retorno geradas pelo modelo Random Forest ajustado.
As previs√µes alimentam uma rotina de aloca√ß√£o √≥tima com foco em maximizar o retorno esperado ajustado ao risco.


## Principais Entregas

- An√°lise explorat√≥ria completa com:
- Treinamento e sele√ß√£o de Modelo de ML
- Otimiza√ß√£o de Portf√≥lio com backtesting e c√°lculos de performance
- Dump do modelo selecionado em .joblib para consumo da API
- API que d√° os pesos √≥timos de cada ticker de tecnologia para maior retorno.

# API Flask ML

Uma API baseada em Flask para retornar os pesos √≥timos de cada ticker para maior retorno.

1. Criar arquivo `.env` (opcional):
```bash
PORT=5000
```

## Executando a API

```bash
python api.py
```

## Endpoints da API

- `GET /health`: Endpoint de verifica√ß√£o de sa√∫de
- `POST /api/v1/predict`: Endpoint de predi√ß√£o

### Exemplo de Requisi√ß√£o (predict)

```bash
curl -X POST http://localhost:5000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '
  {
    "user_tickers": ["AAPL", "GOOG", "AMZN", "NFLX", "MSFT", "IBM"],
    "benchmark_ticker": "^GSPC",
    "start_date": "2020-01-01",
    "end_date": "2025-05-15"
}
'
```

Exemplo de resposta:
```json
{
    "prediction": {
        "method": "Machine Learning",
        "predicted_returns_for_allocation": {
            "AAPL": 0.021008336035190856,
            "AMZN": 0.016394787872220068,
            "GOOG": 0.01177844021958414,
            "IBM": 0.004847179685692798,
            "MSFT": 0.007040221264398282,
            "NFLX": 0.018708126613573267
        },
        "returns": 0.2584574456282873,
        "sharpe_ratio": 0.8361334199410123,
        "volatility": 0.28519066448164465,
        "weights": {
            "AAPL": 0.26333795316394804,
            "AMZN": 0.20550746492228456,
            "GOOG": 0.1476418852827547,
            "IBM": 0.06075904226351138,
            "MSFT": 0.08824865779385858,
            "NFLX": 0.23450499657364274
        }
    }
}
```

## Logs

Os logs s√£o armazenados no diret√≥rio `logs` com rota√ß√£o autom√°tica.

## Pr√≥ximos Passos

Implementar um backtest com rebalanceamento peri√≥dico, onde os pesos s√£o recalculados ao longo do tempo, com base apenas nas informa√ß√µes dispon√≠veis at√© cada momento.

Treinar modelos para mais tickers, de forma que o usu√°rio tenha liberdade de montar uma carteira mais diversificada e n√£o somente baseada em tickers de tecnologia.

Tornar a lista de tickers din√¢mica, para que o usu√°rio possa escolher quais tickers deseja incluir na carteira.
---

